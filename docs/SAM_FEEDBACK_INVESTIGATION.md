# Investigation Checklist: Sam's Feedback

Based on Sam's feedback, here's what we need to investigate in the codebase to validate his concerns and identify improvements.

## Executive Summary

**Sam's concerns are VALID. Here's what we found:**

1. ✅ **Daily questions ARE being generated as questions, not statements** - The `generate_neutral_question()` function explicitly asks for "a neutral, open-ended question" which doesn't work with agree/disagree format
2. ✅ **Discussion titles can be verbose** - No clarity/comprehensibility requirements in the generation prompt
3. ✅ **Geolocation is fully AI-inferred** - No validation or manual override, prone to errors
4. ✅ **Heavy AI automation** - Daily questions auto-publish without human review
5. ⚠️ **Binary vs. Likert** - Design decision, but system could support Likert with changes
6. ⚠️ **Cold-start** - No seeding mechanism currently exists

---

## Quick Findings

### 1. Daily Question Format Issue - CONFIRMED

**Root Cause Found:**
- `app/trending/clustering.py` line 285-295: `generate_neutral_question()` explicitly asks AI to "generate a neutral, open-ended question"
- `app/daily/auto_selection.py` line 143: When using trending topics, if no seed statements exist, it uses `selected.title` which is a QUESTION
- Daily questions need to be STATEMENTS (claims you can agree/disagree with), not QUESTIONS

**The Problem:**
```python
# clustering.py line 285-290
prompt = f"""...generate a neutral, open-ended question suitable for public deliberation.
The question should:
- Be neutral, not leading
- Invite multiple perspectives
...
Return ONLY the question, nothing else."""
```

This generates questions like: "Will traditional news outlets adapt quickly enough?" which doesn't work with agree/disagree.

**The Fix Needed:**
- Change prompt to generate statements, not questions
- Or add a "statement-ifier" that converts questions to statements
- Ensure seed statements are always available (they're statements, not questions)

### 2. Verbose Headlines - CONFIRMED

**Root Cause:**
- Same `generate_neutral_question()` function generates discussion titles
- Prompt says "under 150 characters" but no clarity/comprehensibility requirements
- No validation for jargon, complexity, or readability

**Example Problem:**
- "How can political parties balance accountability with collaboration when navigating reforms influenced by civil service dynamics?"
- 119 chars, but verbose, bureaucratic, hard to parse

**The Fix Needed:**
- Add prompt requirements: "Use simple, direct language. Avoid bureaucratic jargon. Maximum 2 clauses."
- Add readability scoring
- Human review step before publishing

### 3. Geolocation Errors - CONFIRMED

**Root Cause:**
- `app/trending/scorer.py` line 333: AI infers country from article headlines
- No validation that detected country matches article content
- Fallback to source country can be wrong (US source reporting UK story)

**The Fix Needed:**
- Validate detected country appears in article title/summary
- Add manual override in admin interface
- Flag ambiguous cases for human review

### 4. AI Overuse - CONFIRMED

**Current State:**
- Daily questions: Fully automated (auto-selected, auto-published)
- Discussion titles: Auto-generated, no human review
- Seed statements: Auto-generated
- Geographic detection: Fully automated

**The Fix Needed:**
- Add "pending_review" status for daily questions
- Require admin approval before auto-publishing
- Add quality scoring to flag items needing review

---

## 1. Daily Questions That Don't Fit Agree/Disagree Format

### Files to Check:
- `app/daily/auto_selection.py` - How questions are selected
- `app/trending/clustering.py` (lines 274-315) - `generate_neutral_question()` function
- `app/trending/seed_generator.py` - Seed statement generation

### Key Questions:
1. **Is there validation that questions are voteable statements?**
   - Check if `question_text` is validated to be a clear claim/statement
   - Look for any checks that prevent complex multi-part questions
   - See if there's filtering for questions that require nuanced responses

2. **What prompts are used for question generation?**
   - `generate_neutral_question()` in `clustering.py` (line 285-295) - generates "neutral, open-ended questions"
   - This might be the problem - it generates QUESTIONS, not STATEMENTS
   - Daily questions should be statements you can agree/disagree with, not questions

3. **How are seed statements selected for daily questions?**
   - `auto_selection.py` line 130: Uses `selected_statement.content` directly
   - Line 141: Falls back to `selected.title` if no seed statements
   - **ISSUE**: If it falls back to topic title, that's likely a question, not a statement

4. **What happens when trending topics are used?**
   - Line 143: `question_text = selected.title` - uses the topic title directly
   - Topic titles are generated by `generate_neutral_question()` which creates QUESTIONS
   - **This is likely the source of the problem**

### Action Items:
- [ ] Check recent daily questions in database - are they questions or statements?
- [ ] Review `generate_neutral_question()` prompt - does it generate questions or statements?
- [ ] Check if seed statements are always available when using trending topics
- [ ] Add validation to ensure daily questions are voteable statements (not questions)
- [ ] Consider adding a "statement-ifier" that converts questions to statements

---

## 2. Verbose/Incomprehensible Discussion Headlines

### Files to Check:
- `app/trending/clustering.py` (lines 274-315) - `generate_neutral_question()`
- `app/trending/publisher.py` (line 129) - Discussion title assignment
- `app/models.py` - Discussion model (title field length limits)

### Key Questions:
1. **What are the length limits?**
   - Discussion.title is `db.String(200)` - max 200 characters
   - But no validation for clarity/comprehensibility

2. **What prompt generates discussion titles?**
   - `generate_neutral_question()` prompt (line 285-295):
     - "Be under 150 characters" - but no clarity requirements
     - "Focus on policy/civic implications" - might lead to verbose academic language
     - No requirement for simplicity or readability

3. **Are there any quality checks?**
   - No apparent validation for:
     - Readability/comprehensibility
     - Avoiding jargon
     - Keeping it concise
     - Human review before publishing

4. **Example of problematic headline:**
   - "How can political parties balance accountability with collaboration when navigating reforms influenced by civil service dynamics?"
   - This is 119 characters but very verbose and hard to parse
   - Multiple clauses, abstract concepts, bureaucratic language

### Action Items:
- [ ] Review recent discussion titles in database for verbosity
- [ ] Check if `generate_neutral_question()` prompt needs tightening
- [ ] Add readability/complexity scoring
- [ ] Consider adding human review step before publishing
- [ ] Add prompt requirement: "Use simple, direct language. Avoid bureaucratic jargon. Maximum 2 clauses."

---

## 3. Geolocation Errors (UK Stories Marked as US)

### Files to Check:
- `app/trending/scorer.py` (lines 300-405) - Geographic detection
- `app/trending/publisher.py` (lines 41-84) - `_extract_geographic_info()`
- `app/trending/clustering.py` (lines 24-68) - `extract_geographic_info_from_articles()`

### Key Questions:
1. **How is geographic location determined?**
   - `scorer.py` line 333: AI analyzes headlines and returns country names
   - Uses OpenAI/Anthropic to infer from article content
   - **Problem**: AI inference can be unreliable, especially for:
     - Articles mentioning multiple countries
     - International stories with UK angle
     - Stories about UK policies that mention US comparisons

2. **What's the fallback logic?**
   - `publisher.py` line 58: Falls back to `article.source.country`
   - But if source country is wrong (e.g., US news source reporting UK story), error propagates

3. **Is there validation?**
   - No apparent validation that detected country matches article content
   - No manual override capability visible
   - No flagging of ambiguous cases

4. **How are multiple countries handled?**
   - `publisher.py` line 80: Takes most common country from list
   - If article mentions both UK and US, might pick wrong one

### Action Items:
- [ ] Check recent discussions for geolocation errors
- [ ] Review the AI prompt for geographic detection - is it specific enough?
- [ ] Add validation: check if detected country appears in article title/summary
- [ ] Add manual override capability in admin interface
- [ ] Flag ambiguous cases for human review
- [ ] Consider using article source country as primary, AI as secondary

---

## 4. AI Overuse - Where Should Humans Step In?

### Files to Check:
- `app/trending/clustering.py` - Question/title generation
- `app/trending/seed_generator.py` - Seed statement generation
- `app/trending/scorer.py` - Article scoring and geographic detection
- `app/brief/generator.py` - Brief content generation

### Key Questions:
1. **What's fully automated vs. human-reviewed?**
   - Daily questions: Auto-selected, auto-published (line 281-308 in auto_selection.py)
   - Discussion titles: Auto-generated from trending topics
   - Seed statements: Auto-generated
   - Geographic detection: Fully automated
   - **No apparent human review step before publishing**

2. **Where would human curation help most?**
   - Daily question selection - should be human-curated or at least reviewed
   - Discussion titles - definitely need human review for clarity
   - Seed statements - could be human-curated for quality
   - Geographic detection - needs validation/override

3. **What's the current workflow?**
   - Trending topics go through: `pending -> held -> pending_review -> approved -> published`
   - But daily questions bypass this - they're auto-created and auto-published
   - Discussion titles come from trending topics, which might be reviewed, but titles themselves aren't

### Action Items:
- [ ] Map current automation vs. human review workflow
- [ ] Identify bottlenecks where human review would improve quality
- [ ] Consider adding "pending_review" status for daily questions
- [ ] Add admin interface for reviewing/editing auto-generated content
- [ ] Create quality scoring system to flag items needing review

---

## 5. Binary vs. Likert Scale (Design Decision)

### Files to Check:
- `app/daily/constants.py` - Vote mappings
- `app/models.py` - DailyQuestionResponse model
- `app/daily/routes.py` - Vote handling

### Key Questions:
1. **Is the system flexible enough for other formats?**
   - Currently hardcoded: `agree: 1, disagree: -1, unsure: 0`
   - No apparent support for Likert scale (1-5 or 1-7)
   - Would require schema changes to support

2. **What would need to change?**
   - Database schema: `vote` column is `SmallInteger` - could support 1-7
   - Frontend: Would need different UI component
   - Analysis: Consensus clustering might need adjustment for Likert data

3. **Is this worth investigating now?**
   - This is more of a philosophical/design decision
   - But worth checking if system architecture allows for future flexibility

### Action Items:
- [ ] Review if current schema could support Likert scale without breaking changes
- [ ] Consider A/B testing binary vs. Likert for certain question types
- [ ] Document the trade-offs for social science rigor

---

## 6. Cold-Start Problem (User Engagement)

### Files to Check:
- `app/models.py` - Discussion, Statement models
- `app/discussions/statements.py` - Statement creation
- Any seeding/synthetic user logic

### Key Questions:
1. **Is there any seeding mechanism?**
   - No apparent synthetic user system
   - No Twitter poll integration
   - Discussions start empty and rely on organic participation

2. **What could be implemented?**
   - Synthetic users (with transparency)
   - Import from external sources (Reddit, Twitter polls)
   - Pre-populate with diverse seed statements

### Action Items:
- [ ] Research synthetic user approaches (with transparency)
- [ ] Consider Twitter/X API integration for polls
- [ ] Evaluate Reddit data import (with attribution)
- [ ] Document ethical considerations

---

## Priority Investigation Order

1. **HIGH PRIORITY** - Daily question format (questions vs. statements)
2. **HIGH PRIORITY** - Discussion title verbosity/clarity
3. **MEDIUM PRIORITY** - Geolocation errors
4. **MEDIUM PRIORITY** - AI overuse / human review workflow
5. **LOW PRIORITY** - Binary vs. Likert scale (design decision)
6. **LOW PRIORITY** - Cold-start problem (feature request)

---

## Quick Wins

1. **Fix daily question generation prompt** - Change from "generate a question" to "generate a voteable statement"
2. **Add title clarity requirements** - Update prompt to require simple, direct language
3. **Add geolocation validation** - Check if detected country appears in article content
4. **Add human review step** - Require admin approval before auto-publishing daily questions

---

## Database Queries to Run

```sql
-- Check recent daily questions - are they questions or statements?
SELECT question_text, question_date 
FROM daily_question 
WHERE question_date >= CURRENT_DATE - INTERVAL '30 days'
ORDER BY question_date DESC;

-- Check discussion titles for verbosity
SELECT title, LENGTH(title) as title_length, created_at
FROM discussion
WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
ORDER BY LENGTH(title) DESC
LIMIT 20;

-- Check geolocation accuracy (UK discussions marked as US)
SELECT d.id, d.title, d.country, d.geographic_scope, d.created_at
FROM discussion d
WHERE d.country = 'United States'
AND (d.title ILIKE '%uk%' OR d.title ILIKE '%britain%' OR d.title ILIKE '%london%')
ORDER BY d.created_at DESC;
```
